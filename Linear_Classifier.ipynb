{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYjxAIaxEm7Q",
        "colab_type": "code",
        "outputId": "b2d639fe-24d2-472e-d144-a7112a739e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install mnist\n",
        "import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4t1DOqFEm7T",
        "colab_type": "text"
      },
      "source": [
        "# Linear Classifer\n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHH0oPyTEm7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(num):\n",
        "    logits = 1 / (1 + np.exp(-num))\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCwp8i4Em7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_classifier(train_data, train_labels, loss = 'softmax'):\n",
        "    weights = np.random.rand(train_data.shape[1], 1)\n",
        "    bias = np.zeros((1))\n",
        "    ,\n",
        "    # forward \n",
        "    pre_activation = np.dot(train_data, weights) + bias\n",
        "    out = sigmoid(pre_activation)\n",
        "    return out, train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PweBlp5jEm7Z",
        "colab_type": "code",
        "outputId": "d695beda-d2e8-41d6-c813-4959d6582a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "linear_classifier(np.random.rand(5,6), np.random.randint(2, size=5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.81854941],\n",
              "        [0.80614069],\n",
              "        [0.73719947],\n",
              "        [0.87506132],\n",
              "        [0.74351717]]), array([0, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG0XZesDEm7d",
        "colab_type": "text"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsGG1Y5EEm7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(out, actual):\n",
        "    return np.mean(- actual * out - (1 - actual) * out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpZJn0dfEm7g",
        "colab_type": "code",
        "outputId": "e26e2d47-dd70-4ed5-945f-111e6d991874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'This is the mean loss {loss(np.random.rand(7), np.random.randint(2, size=7))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the mean loss -0.5634688501808093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R94-UA2XEm7j",
        "colab_type": "text"
      },
      "source": [
        "## Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K4BacSSEm7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient(x, out, actual):\n",
        "    loss_diff = out - actual # diffrentiation for the loss function\n",
        "    print(loss_diff.shape, x.T.shape) # \n",
        "    gradient = np.dot(x.T, loss_diff) # chaining of derivative\n",
        "    return gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHqztfEwEm7m",
        "colab_type": "code",
        "outputId": "fd39fb8e-e383-4ee1-c50f-42ec032957d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "out, actual = linear_classifier(np.random.rand(2,5) ,np.random.randint(2, size=1))\n",
        "gradient(np.random.rand(2,5), out, actual)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1) (5, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.08096959],\n",
              "       [-0.17685766],\n",
              "       [-0.20454018],\n",
              "       [-0.2410765 ],\n",
              "       [-0.31738464]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce6nsl5BEm7q",
        "colab_type": "text"
      },
      "source": [
        "## \"Class\"-ifying it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfd7Sut3Em7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.01, num_iter=10000, fit_intercept=True, verbose=True):\n",
        "        self.lr = lr\n",
        "        self.num_iter = num_iter\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.verbose = verbose\n",
        "        self.theta = None\n",
        "    \n",
        "    def __add_intercept(self, X):\n",
        "        intercept = np.ones((X.shape[0], 1))\n",
        "        return np.concatenate((intercept, X), axis=1)\n",
        "    \n",
        "    def __sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    def __loss(self, h, y):\n",
        "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "        \n",
        "        # weights initialization\n",
        "        self.theta = np.zeros(X.shape[1])\n",
        "        \n",
        "        for i in range(self.num_iter):\n",
        "            z = np.dot(X, self.theta)\n",
        "            h = self.__sigmoid(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / y.size\n",
        "            self.theta -= self.lr * gradient\n",
        "            \n",
        "            z = np.dot(X, self.theta)\n",
        "            h = self.__sigmoid(z)\n",
        "            loss = self.__loss(h, y)\n",
        "                \n",
        "            if(self.verbose ==True and i % 500 == 0):\n",
        "                print(f'loss: {loss} \\t')\n",
        "    \n",
        "    def predict_prob(self, X):\n",
        "        if self.fit_intercept:\n",
        "            X = self.__add_intercept(X)\n",
        "    \n",
        "        return self.__sigmoid(np.dot(X, self.theta))\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return self.predict_prob(X).round()\n",
        "    \n",
        "    def give_weights(self):\n",
        "        return self.theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2wvk0HdEm7t",
        "colab_type": "code",
        "outputId": "ca21ad36-23b3-4613-af50-74462b4c6fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_images = mnist.train_images()/255.\n",
        "train_images = train_images.reshape(train_images.shape[0], -1)\n",
        "train_labels = mnist.train_labels()\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmSqgPZXEm7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LogisticRegression(lr = 0.001, num_iter = 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjFOcuBnEm7z",
        "colab_type": "text"
      },
      "source": [
        "# Only Classifying a Single digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scXwY27MEm7z",
        "colab_type": "code",
        "outputId": "3c0eee50-1d82-457f-c3c9-dfda969673b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWBX5DKEm74",
        "colab_type": "code",
        "outputId": "4fab5d48-9f7e-447f-c93b-a9e4554f8daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "train_labels = np.array([ 1 if x==7 else 0 for x in train_labels ])\n",
        "\n",
        "print(train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAyQGH3Em76",
        "colab_type": "code",
        "outputId": "1914c4b2-9422-4172-eb36-0ebb5c16b0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.fit(train_images[:1000], train_labels[:1000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6875525831455905 \t\n",
            "loss: 0.29546765261842506 \t\n",
            "loss: 0.24747210896523839 \t\n",
            "loss: 0.21517494144922053 \t\n",
            "loss: 0.19216357442786874 \t\n",
            "loss: 0.17518576679803963 \t\n",
            "loss: 0.1622057667162103 \t\n",
            "loss: 0.1519623964082686 \t\n",
            "loss: 0.14365822167341197 \t\n",
            "loss: 0.1367727452397071 \t\n",
            "loss: 0.13095484242615105 \t\n",
            "loss: 0.125960231256864 \t\n",
            "loss: 0.12161417260818064 \t\n",
            "loss: 0.11778854447681032 \t\n",
            "loss: 0.11438732540199467 \t\n",
            "loss: 0.11133714119766418 \t\n",
            "loss: 0.10858094790371017 \t\n",
            "loss: 0.10607370988727753 \t\n",
            "loss: 0.10377937899248545 \t\n",
            "loss: 0.10166874163582179 \t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDoMfcIAIrG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_reg = (model.give_weights()[:784].reshape(28,28) * 255).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQzDNS2bJRQ9",
        "colab_type": "code",
        "outputId": "0c53f464-4322-4539-fff2-8f51c80e38e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(filter_reg, cmap='binary')   # This figure shows that a LR basically takes average values of multiple hot sample, this is only to draw intuition :)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff747230588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIrwA0kRfiCp/wdfC0zP3Cp8iwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}